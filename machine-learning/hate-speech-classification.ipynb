{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-06T07:04:13.875171Z","iopub.execute_input":"2023-06-06T07:04:13.875528Z","iopub.status.idle":"2023-06-06T07:04:13.893370Z","shell.execute_reply.started":"2023-06-06T07:04:13.875498Z","shell.execute_reply":"2023-06-06T07:04:13.892215Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/hate-speech-classification/CaseFolded_PunctRemoved_RTUserRemovedTest.csv\n/kaggle/input/hate-speech-classification/CaseFolded_PunctRemoved_RTUserRemovedTrain.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertModel","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:04:13.895986Z","iopub.execute_input":"2023-06-06T07:04:13.897049Z","iopub.status.idle":"2023-06-06T07:04:19.574669Z","shell.execute_reply.started":"2023-06-06T07:04:13.897017Z","shell.execute_reply":"2023-06-06T07:04:19.573770Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/hate-speech-classification/CaseFolded_PunctRemoved_RTUserRemovedTrain.csv')\ntest_df = pd.read_csv('/kaggle/input/hate-speech-classification/CaseFolded_PunctRemoved_RTUserRemovedTest.csv')\n\ntweets = train_df['Tweet'].tolist()\ntargets = train_df[['HS_Religion', 'HS_Race', 'HS_Physical', 'HS_Gender', 'HS_Other', \n                    'HS_Individual', 'HS_Group', 'HS_Weak', 'HS_Moderate', 'HS_Strong']].values.tolist()\n\ntest_tweets = test_df['Tweet'].tolist()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:04:19.576498Z","iopub.execute_input":"2023-06-06T07:04:19.576837Z","iopub.status.idle":"2023-06-06T07:04:19.607423Z","shell.execute_reply.started":"2023-06-06T07:04:19.576805Z","shell.execute_reply":"2023-06-06T07:04:19.606542Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('indolem/indobert-base-uncased')\nmax_length = 128\nlr = 2e-5\nepochs = 20\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:04:19.608951Z","iopub.execute_input":"2023-06-06T07:04:19.609276Z","iopub.status.idle":"2023-06-06T07:04:19.736386Z","shell.execute_reply.started":"2023-06-06T07:04:19.609240Z","shell.execute_reply":"2023-06-06T07:04:19.735436Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Pembuatan Dataset\nclass HateSpeechDataset(Dataset):\n    def __init__(self, tweets, targets, tokenizer, max_length):\n        self.tweets = tweets\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __len__(self):\n        return len(self.tweets)\n    \n    def __getitem__(self, index):\n        tweet = self.tweets[index]\n        target = self.targets[index]\n        \n        encoding = self.tokenizer.encode_plus(\n            tweet,\n            add_special_tokens=True,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n        \n        input_ids = encoding['input_ids'].squeeze()\n        attention_mask = encoding['attention_mask'].squeeze()\n        \n        return {\n            'input_ids': input_ids,\n            'attention_mask': attention_mask,\n            'target': torch.tensor(target, dtype=torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:02:59.548693Z","iopub.execute_input":"2023-06-06T08:02:59.549786Z","iopub.status.idle":"2023-06-06T08:02:59.558083Z","shell.execute_reply.started":"2023-06-06T08:02:59.549751Z","shell.execute_reply":"2023-06-06T08:02:59.556971Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"class HateSpeechClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(HateSpeechClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained('indolem/indobert-base-uncased')\n        self.dropout = nn.Dropout(0.2)\n        self.relu = nn.ReLU()\n        self.fc1 = nn.Linear(768, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, 10)\n        self.softmax = nn.Sigmoid()\n        \n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids, attention_mask=attention_mask)[0]\n        pooled_output = outputs[:, 0, :]\n        pooled_output = self.dropout(pooled_output)\n        \n        linear_output1 = self.relu(self.fc1(pooled_output))\n        linear_output2 = self.relu(self.fc2(linear_output1))\n        linear_output3 = self.fc3(linear_output2)\n        \n        logits = self.softmax(linear_output3)\n        \n        return logits\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:04:19.749622Z","iopub.execute_input":"2023-06-06T07:04:19.750562Z","iopub.status.idle":"2023-06-06T07:04:19.763423Z","shell.execute_reply.started":"2023-06-06T07:04:19.750529Z","shell.execute_reply":"2023-06-06T07:04:19.762517Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_tweets, val_tweets, train_targets, val_targets = train_test_split(tweets, targets, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:04:19.764690Z","iopub.execute_input":"2023-06-06T07:04:19.765136Z","iopub.status.idle":"2023-06-06T07:04:19.776561Z","shell.execute_reply.started":"2023-06-06T07:04:19.765104Z","shell.execute_reply":"2023-06-06T07:04:19.775671Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_dataset = HateSpeechDataset(train_tweets, train_targets, tokenizer, max_length)\nval_dataset = HateSpeechDataset(val_tweets, val_targets, tokenizer, max_length)\ntest_dataset = HateSpeechDataset(test_tweets, [], tokenizer, max_length)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:04:19.777941Z","iopub.execute_input":"2023-06-06T07:04:19.778305Z","iopub.status.idle":"2023-06-06T07:04:19.788165Z","shell.execute_reply.started":"2023-06-06T07:04:19.778274Z","shell.execute_reply":"2023-06-06T07:04:19.787119Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model = HateSpeechClassifier(num_classes=len(train_targets[0]))\noptimizer = torch.optim.AdamW(model.parameters(), lr=lr)\ncriterion = nn.BCELoss()\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\ncriterion.to(device)\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:04:19.789619Z","iopub.execute_input":"2023-06-06T07:04:19.790013Z","iopub.status.idle":"2023-06-06T07:04:23.643404Z","shell.execute_reply.started":"2023-06-06T07:04:19.789981Z","shell.execute_reply":"2023-06-06T07:04:23.642352Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"def checkpoint(model, filename):\n    torch.save(model.state_dict(), filename)\n    \ndef resume(model, filename):\n    model.load_state_dict(torch.load(filename))","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:04:23.645118Z","iopub.execute_input":"2023-06-06T07:04:23.645482Z","iopub.status.idle":"2023-06-06T07:04:23.650649Z","shell.execute_reply.started":"2023-06-06T07:04:23.645449Z","shell.execute_reply":"2023-06-06T07:04:23.649790Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:04:23.654370Z","iopub.execute_input":"2023-06-06T07:04:23.655057Z","iopub.status.idle":"2023-06-06T07:04:23.664474Z","shell.execute_reply.started":"2023-06-06T07:04:23.655025Z","shell.execute_reply":"2023-06-06T07:04:23.663474Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Convert logits to corresponding prediction\ndef finalize_prediction(out):    \n    # Handle category\n    category = out[:5]\n    for i in range(5):\n        if category[i] > 0.5:\n            out[i] = 1\n        else:\n            out[i] = 0\n    \n    # Handle individual/group target\n    i = 5\n    if out[i] >= out[i+1]:\n        out[i] = 1\n        out[i+1] = 0\n    elif out[i] < out[i+1]:\n        out[i] = 0\n        out[i+1] = 1\n\n    # Handle level of hate\n    i = 7\n    max = out[i]\n    max_idx = i\n    for j in range(1, 3):\n        if out[i+j] > max:\n            max = out[i+j]\n            max_idx = i+j\n    for i in range(7, 10):\n        if i != max_idx:\n            out[i] = 0\n        else:\n            out[i] = 1","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:04:23.665855Z","iopub.execute_input":"2023-06-06T07:04:23.666203Z","iopub.status.idle":"2023-06-06T07:04:23.677413Z","shell.execute_reply.started":"2023-06-06T07:04:23.666173Z","shell.execute_reply":"2023-06-06T07:04:23.676549Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"best_accuracy = 0.0\nfor epoch in range(epochs):\n    model.train()\n    print(f\"Epoch {epoch+1}: Training start\")\n    train_loss = 0.0\n    for batch in train_dataloader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        targets = batch['target'].to(device)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(input_ids, attention_mask)\n        loss = criterion(outputs, targets)\n        loss.backward(retain_graph=True)\n        optimizer.step()\n        \n        train_loss += loss.item() * input_ids.size(0)\n        \n    train_loss /= len(train_dataloader.dataset)\n    print(f\"Epoch {epoch+1}: Training Done\")\n    model.eval()\n    val_loss = 0.0\n    val_preds = []\n    val_targets = []\n    with torch.no_grad():\n        for batch in val_dataloader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            targets = batch['target'].to(device)\n            \n            outputs = model(input_ids, attention_mask)\n            for output in outputs:\n                finalize_prediction(output)\n            loss = criterion(outputs, targets)\n            \n            val_loss += loss.item() * input_ids.size(0)\n            \n            val_preds.extend(targets.cpu().detach().numpy().tolist())\n            val_targets.extend(outputs.cpu().detach().numpy().tolist())\n    acc = accuracy_score(val_targets, val_preds) * 100\n    val_loss /= len(val_dataloader.dataset)\n    \n    print(f'Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}')\n    print(f\"Epoch {epoch+1}: validation accuracy = {acc:.2f}%\")\n    if acc > best_accuracy:\n        best_accuracy = acc\n        checkpoint(model, \"best_model.pth\")\n    print(f\"Epoch {epoch+1}: Validation end\")\n\nresume(model, \"best_model.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:04:23.678813Z","iopub.execute_input":"2023-06-06T07:04:23.679401Z","iopub.status.idle":"2023-06-06T07:24:33.393706Z","shell.execute_reply.started":"2023-06-06T07:04:23.679370Z","shell.execute_reply":"2023-06-06T07:24:33.392663Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1: Training start\nEpoch 1: Training Done\nEpoch 1/20 - Train Loss: 0.5108 - Val Loss: 21.7282\nEpoch 1: validation accuracy = 44.28%\nEpoch 1: Validation end\nEpoch 2: Training start\nEpoch 2: Training Done\nEpoch 2/20 - Train Loss: 0.3974 - Val Loss: 16.7057\nEpoch 2: validation accuracy = 45.81%\nEpoch 2: Validation end\nEpoch 3: Training start\nEpoch 3: Training Done\nEpoch 3/20 - Train Loss: 0.3442 - Val Loss: 15.9406\nEpoch 3: validation accuracy = 45.54%\nEpoch 3: Validation end\nEpoch 4: Training start\nEpoch 4: Training Done\nEpoch 4/20 - Train Loss: 0.2951 - Val Loss: 12.8533\nEpoch 4: validation accuracy = 56.71%\nEpoch 4: Validation end\nEpoch 5: Training start\nEpoch 5: Training Done\nEpoch 5/20 - Train Loss: 0.2455 - Val Loss: 12.2322\nEpoch 5: validation accuracy = 57.07%\nEpoch 5: Validation end\nEpoch 6: Training start\nEpoch 6: Training Done\nEpoch 6/20 - Train Loss: 0.2002 - Val Loss: 12.5203\nEpoch 6: validation accuracy = 57.70%\nEpoch 6: Validation end\nEpoch 7: Training start\nEpoch 7: Training Done\nEpoch 7/20 - Train Loss: 0.1637 - Val Loss: 11.6652\nEpoch 7: validation accuracy = 56.89%\nEpoch 7: Validation end\nEpoch 8: Training start\nEpoch 8: Training Done\nEpoch 8/20 - Train Loss: 0.1357 - Val Loss: 11.2421\nEpoch 8: validation accuracy = 62.02%\nEpoch 8: Validation end\nEpoch 9: Training start\nEpoch 9: Training Done\nEpoch 9/20 - Train Loss: 0.1165 - Val Loss: 11.5572\nEpoch 9: validation accuracy = 60.04%\nEpoch 9: Validation end\nEpoch 10: Training start\nEpoch 10: Training Done\nEpoch 10/20 - Train Loss: 0.1014 - Val Loss: 11.1341\nEpoch 10: validation accuracy = 61.03%\nEpoch 10: Validation end\nEpoch 11: Training start\nEpoch 11: Training Done\nEpoch 11/20 - Train Loss: 0.0953 - Val Loss: 10.9541\nEpoch 11: validation accuracy = 62.38%\nEpoch 11: Validation end\nEpoch 12: Training start\nEpoch 12: Training Done\nEpoch 12/20 - Train Loss: 0.0862 - Val Loss: 10.7021\nEpoch 12: validation accuracy = 62.47%\nEpoch 12: Validation end\nEpoch 13: Training start\nEpoch 13: Training Done\nEpoch 13/20 - Train Loss: 0.0728 - Val Loss: 11.1791\nEpoch 13: validation accuracy = 62.56%\nEpoch 13: Validation end\nEpoch 14: Training start\nEpoch 14: Training Done\nEpoch 14/20 - Train Loss: 0.0678 - Val Loss: 10.8821\nEpoch 14: validation accuracy = 63.01%\nEpoch 14: Validation end\nEpoch 15: Training start\nEpoch 15: Training Done\nEpoch 15/20 - Train Loss: 0.0605 - Val Loss: 11.1341\nEpoch 15: validation accuracy = 62.56%\nEpoch 15: Validation end\nEpoch 16: Training start\nEpoch 16: Training Done\nEpoch 16/20 - Train Loss: 0.0556 - Val Loss: 10.8731\nEpoch 16: validation accuracy = 64.99%\nEpoch 16: Validation end\nEpoch 17: Training start\nEpoch 17: Training Done\nEpoch 17/20 - Train Loss: 0.0584 - Val Loss: 11.1971\nEpoch 17: validation accuracy = 62.20%\nEpoch 17: Validation end\nEpoch 18: Training start\nEpoch 18: Training Done\nEpoch 18/20 - Train Loss: 0.0497 - Val Loss: 11.0711\nEpoch 18: validation accuracy = 65.89%\nEpoch 18: Validation end\nEpoch 19: Training start\nEpoch 19: Training Done\nEpoch 19/20 - Train Loss: 0.0507 - Val Loss: 10.7831\nEpoch 19: validation accuracy = 66.43%\nEpoch 19: Validation end\nEpoch 20: Training start\nEpoch 20: Training Done\nEpoch 20/20 - Train Loss: 0.0476 - Val Loss: 10.2700\nEpoch 20: validation accuracy = 67.15%\nEpoch 20: Validation end\n","output_type":"stream"}]},{"cell_type":"code","source":"resume(model, \"best_model.pth\")","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:24:33.395489Z","iopub.execute_input":"2023-06-06T07:24:33.395846Z","iopub.status.idle":"2023-06-06T07:24:33.660918Z","shell.execute_reply.started":"2023-06-06T07:24:33.395811Z","shell.execute_reply":"2023-06-06T07:24:33.659953Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:36:29.802089Z","iopub.execute_input":"2023-06-06T07:36:29.803070Z","iopub.status.idle":"2023-06-06T07:36:29.817400Z","shell.execute_reply.started":"2023-06-06T07:36:29.803030Z","shell.execute_reply":"2023-06-06T07:36:29.816277Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"       No                                              Tweet\n0  Test-1  pemerintah sekarang pro asing sudah tidak bisa...\n1  Test-2          cebong dungu picek sudah kalah malah gila\n2  Test-3  namanya juga simpang susun bukan bundaran sema...\n3  Test-4  yang tidak pakai jilbab komunis megawati sri m...\n4  Test-5  ramos yang aku pandang idola dahulu sekarang s...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>No</th>\n      <th>Tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Test-1</td>\n      <td>pemerintah sekarang pro asing sudah tidak bisa...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Test-2</td>\n      <td>cebong dungu picek sudah kalah malah gila</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Test-3</td>\n      <td>namanya juga simpang susun bukan bundaran sema...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Test-4</td>\n      <td>yang tidak pakai jilbab komunis megawati sri m...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Test-5</td>\n      <td>ramos yang aku pandang idola dahulu sekarang s...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"submission_sample = pd.read_csv('/kaggle/input/hate-speech-classification/sample.csv')\nsubmission_sample.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T07:41:45.768002Z","iopub.execute_input":"2023-06-06T07:41:45.768758Z","iopub.status.idle":"2023-06-06T07:41:45.792395Z","shell.execute_reply.started":"2023-06-06T07:41:45.768719Z","shell.execute_reply":"2023-06-06T07:41:45.791081Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"       No  HS_Religion  HS_Race  HS_Physical  HS_Gender  HS_Other  \\\n0  Test-1            0        0            0          0         0   \n1  Test-2            0        0            0          0         0   \n2  Test-3            0        0            0          0         0   \n3  Test-4            0        0            0          0         0   \n4  Test-5            0        0            0          0         0   \n\n   HS_Individual  HS_Group  HS_Weak  HS_Moderate  HS_Strong  \n0              0         0        0            0          0  \n1              0         0        0            0          0  \n2              0         0        0            0          0  \n3              0         0        0            0          0  \n4              0         0        0            0          0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>No</th>\n      <th>HS_Religion</th>\n      <th>HS_Race</th>\n      <th>HS_Physical</th>\n      <th>HS_Gender</th>\n      <th>HS_Other</th>\n      <th>HS_Individual</th>\n      <th>HS_Group</th>\n      <th>HS_Weak</th>\n      <th>HS_Moderate</th>\n      <th>HS_Strong</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Test-1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Test-2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Test-3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Test-4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Test-5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Extract dummy target from submission sample & concat it to cleaned training data\ntarget_list = [\n    'HS_Religion', 'HS_Race', 'HS_Physical', 'HS_Gender',\n    'HS_Other', 'HS_Individual', 'HS_Group', 'HS_Weak', \n    'HS_Moderate', 'HS_Strong'\n]","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:14:14.828788Z","iopub.execute_input":"2023-06-06T08:14:14.829497Z","iopub.status.idle":"2023-06-06T08:14:14.834242Z","shell.execute_reply.started":"2023-06-06T08:14:14.829463Z","shell.execute_reply":"2023-06-06T08:14:14.833290Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/hate-speech-classification/CaseFolded_PunctRemoved_RTUserRemovedTest.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:28:35.507583Z","iopub.execute_input":"2023-06-06T08:28:35.507966Z","iopub.status.idle":"2023-06-06T08:28:35.516284Z","shell.execute_reply.started":"2023-06-06T08:28:35.507930Z","shell.execute_reply":"2023-06-06T08:28:35.515404Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:14:44.203306Z","iopub.execute_input":"2023-06-06T08:14:44.203663Z","iopub.status.idle":"2023-06-06T08:14:44.213581Z","shell.execute_reply.started":"2023-06-06T08:14:44.203634Z","shell.execute_reply":"2023-06-06T08:14:44.212588Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"       No                                              Tweet\n0  Test-1  pemerintah sekarang pro asing sudah tidak bisa...\n1  Test-2          cebong dungu picek sudah kalah malah gila\n2  Test-3  namanya juga simpang susun bukan bundaran sema...\n3  Test-4  yang tidak pakai jilbab komunis megawati sri m...\n4  Test-5  ramos yang aku pandang idola dahulu sekarang s...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>No</th>\n      <th>Tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Test-1</td>\n      <td>pemerintah sekarang pro asing sudah tidak bisa...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Test-2</td>\n      <td>cebong dungu picek sudah kalah malah gila</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Test-3</td>\n      <td>namanya juga simpang susun bukan bundaran sema...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Test-4</td>\n      <td>yang tidak pakai jilbab komunis megawati sri m...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Test-5</td>\n      <td>ramos yang aku pandang idola dahulu sekarang s...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dummy_target = pd.DataFrame(submission_sample[target_list].values, columns=target_list)\ndummy_target","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:14:56.345837Z","iopub.execute_input":"2023-06-06T08:14:56.346775Z","iopub.status.idle":"2023-06-06T08:14:56.366571Z","shell.execute_reply.started":"2023-06-06T08:14:56.346742Z","shell.execute_reply":"2023-06-06T08:14:56.365719Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"     HS_Religion  HS_Race  HS_Physical  HS_Gender  HS_Other  HS_Individual  \\\n0              0        0            0          0         0              0   \n1              0        0            0          0         0              0   \n2              0        0            0          0         0              0   \n3              0        0            0          0         0              0   \n4              0        0            0          0         0              0   \n..           ...      ...          ...        ...       ...            ...   \n145            0        0            0          0         0              0   \n146            0        0            0          0         0              0   \n147            0        0            0          0         0              0   \n148            0        0            0          0         0              0   \n149            0        0            0          0         0              0   \n\n     HS_Group  HS_Weak  HS_Moderate  HS_Strong  \n0           0        0            0          0  \n1           0        0            0          0  \n2           0        0            0          0  \n3           0        0            0          0  \n4           0        0            0          0  \n..        ...      ...          ...        ...  \n145         0        0            0          0  \n146         0        0            0          0  \n147         0        0            0          0  \n148         0        0            0          0  \n149         0        0            0          0  \n\n[150 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HS_Religion</th>\n      <th>HS_Race</th>\n      <th>HS_Physical</th>\n      <th>HS_Gender</th>\n      <th>HS_Other</th>\n      <th>HS_Individual</th>\n      <th>HS_Group</th>\n      <th>HS_Weak</th>\n      <th>HS_Moderate</th>\n      <th>HS_Strong</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 10 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test = pd.concat([df_test, dummy_target], axis=1)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:28:14.318713Z","iopub.execute_input":"2023-06-06T08:28:14.319096Z","iopub.status.idle":"2023-06-06T08:28:14.334575Z","shell.execute_reply.started":"2023-06-06T08:28:14.319063Z","shell.execute_reply":"2023-06-06T08:28:14.333172Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"       No                                              Tweet  HS_Religion  \\\n0  Test-1  pemerintah sekarang pro asing sudah tidak bisa...            0   \n1  Test-2          cebong dungu picek sudah kalah malah gila            0   \n2  Test-3  namanya juga simpang susun bukan bundaran sema...            0   \n3  Test-4  yang tidak pakai jilbab komunis megawati sri m...            0   \n4  Test-5  ramos yang aku pandang idola dahulu sekarang s...            0   \n\n   HS_Race  HS_Physical  HS_Gender  HS_Other  HS_Individual  HS_Group  \\\n0        0            0          0         0              0         0   \n1        0            0          0         0              0         0   \n2        0            0          0         0              0         0   \n3        0            0          0         0              0         0   \n4        0            0          0         0              0         0   \n\n   HS_Weak  HS_Moderate  HS_Strong  \n0        0            0          0  \n1        0            0          0  \n2        0            0          0  \n3        0            0          0  \n4        0            0          0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>No</th>\n      <th>Tweet</th>\n      <th>HS_Religion</th>\n      <th>HS_Race</th>\n      <th>HS_Physical</th>\n      <th>HS_Gender</th>\n      <th>HS_Other</th>\n      <th>HS_Individual</th>\n      <th>HS_Group</th>\n      <th>HS_Weak</th>\n      <th>HS_Moderate</th>\n      <th>HS_Strong</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Test-1</td>\n      <td>pemerintah sekarang pro asing sudah tidak bisa...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Test-2</td>\n      <td>cebong dungu picek sudah kalah malah gila</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Test-3</td>\n      <td>namanya juga simpang susun bukan bundaran sema...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Test-4</td>\n      <td>yang tidak pakai jilbab komunis megawati sri m...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Test-5</td>\n      <td>ramos yang aku pandang idola dahulu sekarang s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:15:22.343483Z","iopub.execute_input":"2023-06-06T08:15:22.343835Z","iopub.status.idle":"2023-06-06T08:15:22.359058Z","shell.execute_reply.started":"2023-06-06T08:15:22.343805Z","shell.execute_reply":"2023-06-06T08:15:22.358199Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"           No                                              Tweet  HS_Religion  \\\n0      Test-1  pemerintah sekarang pro asing sudah tidak bisa...            0   \n1      Test-2          cebong dungu picek sudah kalah malah gila            0   \n2      Test-3  namanya juga simpang susun bukan bundaran sema...            0   \n3      Test-4  yang tidak pakai jilbab komunis megawati sri m...            0   \n4      Test-5  ramos yang aku pandang idola dahulu sekarang s...            0   \n..        ...                                                ...          ...   \n145  Test-146  banyak kader kader partai demokrasi indonesia ...            0   \n146  Test-147                        ternyata buddha pun teroris            0   \n147  Test-148  biasa mereka itulah para antek antek zionis da...            0   \n148  Test-149                            astaga bolot banget dia            0   \n149  Test-150  cina babi itu yang bikin rusak indonesia banta...            0   \n\n     HS_Race  HS_Physical  HS_Gender  HS_Other  HS_Individual  HS_Group  \\\n0          0            0          0         0              0         0   \n1          0            0          0         0              0         0   \n2          0            0          0         0              0         0   \n3          0            0          0         0              0         0   \n4          0            0          0         0              0         0   \n..       ...          ...        ...       ...            ...       ...   \n145        0            0          0         0              0         0   \n146        0            0          0         0              0         0   \n147        0            0          0         0              0         0   \n148        0            0          0         0              0         0   \n149        0            0          0         0              0         0   \n\n     HS_Weak  HS_Moderate  HS_Strong  \n0          0            0          0  \n1          0            0          0  \n2          0            0          0  \n3          0            0          0  \n4          0            0          0  \n..       ...          ...        ...  \n145        0            0          0  \n146        0            0          0  \n147        0            0          0  \n148        0            0          0  \n149        0            0          0  \n\n[150 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>No</th>\n      <th>Tweet</th>\n      <th>HS_Religion</th>\n      <th>HS_Race</th>\n      <th>HS_Physical</th>\n      <th>HS_Gender</th>\n      <th>HS_Other</th>\n      <th>HS_Individual</th>\n      <th>HS_Group</th>\n      <th>HS_Weak</th>\n      <th>HS_Moderate</th>\n      <th>HS_Strong</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Test-1</td>\n      <td>pemerintah sekarang pro asing sudah tidak bisa...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Test-2</td>\n      <td>cebong dungu picek sudah kalah malah gila</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Test-3</td>\n      <td>namanya juga simpang susun bukan bundaran sema...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Test-4</td>\n      <td>yang tidak pakai jilbab komunis megawati sri m...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Test-5</td>\n      <td>ramos yang aku pandang idola dahulu sekarang s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>Test-146</td>\n      <td>banyak kader kader partai demokrasi indonesia ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>Test-147</td>\n      <td>ternyata buddha pun teroris</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>Test-148</td>\n      <td>biasa mereka itulah para antek antek zionis da...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>Test-149</td>\n      <td>astaga bolot banget dia</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>Test-150</td>\n      <td>cina babi itu yang bikin rusak indonesia banta...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_tweets = df_test['Tweet'].tolist()\ntest_dataset = HateSpeechDataset(test_tweets, df_test[target_list].values.tolist(), tokenizer, max_length)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:16:08.594718Z","iopub.execute_input":"2023-06-06T08:16:08.595115Z","iopub.status.idle":"2023-06-06T08:16:08.602264Z","shell.execute_reply.started":"2023-06-06T08:16:08.595083Z","shell.execute_reply":"2023-06-06T08:16:08.601359Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"output_labels = []\nwith torch.no_grad():\n    for batch_data in test_dataloader:\n        # Unpack batch_data\n        ids = batch_data['input_ids'].to(device)\n        mask = batch_data['attention_mask'].to(device)\n        \n        # Saving output\n        outputs = model(ids, mask)\n        for output in outputs:\n            finalize_prediction(output)\n        output_labels.extend(outputs.cpu().detach().numpy().tolist())","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:16:13.761930Z","iopub.execute_input":"2023-06-06T08:16:13.762293Z","iopub.status.idle":"2023-06-06T08:16:14.543730Z","shell.execute_reply.started":"2023-06-06T08:16:13.762264Z","shell.execute_reply":"2023-06-06T08:16:14.542764Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"model_preds = pd.DataFrame(output_labels, columns=target_list)\nmodel_preds.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:17:07.374065Z","iopub.execute_input":"2023-06-06T08:17:07.374456Z","iopub.status.idle":"2023-06-06T08:17:07.395104Z","shell.execute_reply.started":"2023-06-06T08:17:07.374426Z","shell.execute_reply":"2023-06-06T08:17:07.394054Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"   HS_Religion  HS_Race  HS_Physical  HS_Gender  HS_Other  HS_Individual  \\\n0          0.0      0.0          0.0        0.0       1.0            1.0   \n1          0.0      0.0          0.0        0.0       1.0            0.0   \n2          0.0      0.0          0.0        0.0       1.0            0.0   \n3          0.0      0.0          0.0        0.0       1.0            0.0   \n4          0.0      0.0          0.0        0.0       1.0            0.0   \n\n   HS_Group  HS_Weak  HS_Moderate  HS_Strong  \n0       0.0      0.0          0.0        1.0  \n1       1.0      0.0          1.0        0.0  \n2       1.0      0.0          1.0        0.0  \n3       1.0      0.0          1.0        0.0  \n4       1.0      0.0          1.0        0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HS_Religion</th>\n      <th>HS_Race</th>\n      <th>HS_Physical</th>\n      <th>HS_Gender</th>\n      <th>HS_Other</th>\n      <th>HS_Individual</th>\n      <th>HS_Group</th>\n      <th>HS_Weak</th>\n      <th>HS_Moderate</th>\n      <th>HS_Strong</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"model_preds.to_csv('prediction.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:17:56.040699Z","iopub.execute_input":"2023-06-06T08:17:56.041086Z","iopub.status.idle":"2023-06-06T08:17:56.049565Z","shell.execute_reply.started":"2023-06-06T08:17:56.041054Z","shell.execute_reply":"2023-06-06T08:17:56.048563Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"df_test = pd.concat([df_test, model_preds], axis=1)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:28:45.873258Z","iopub.execute_input":"2023-06-06T08:28:45.873641Z","iopub.status.idle":"2023-06-06T08:28:45.898019Z","shell.execute_reply.started":"2023-06-06T08:28:45.873609Z","shell.execute_reply":"2023-06-06T08:28:45.896972Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"       No                                              Tweet  HS_Religion  \\\n0  Test-1  pemerintah sekarang pro asing sudah tidak bisa...          0.0   \n1  Test-2          cebong dungu picek sudah kalah malah gila          0.0   \n2  Test-3  namanya juga simpang susun bukan bundaran sema...          0.0   \n3  Test-4  yang tidak pakai jilbab komunis megawati sri m...          0.0   \n4  Test-5  ramos yang aku pandang idola dahulu sekarang s...          0.0   \n\n   HS_Race  HS_Physical  HS_Gender  HS_Other  HS_Individual  HS_Group  \\\n0      0.0          0.0        0.0       1.0            1.0       0.0   \n1      0.0          0.0        0.0       1.0            0.0       1.0   \n2      0.0          0.0        0.0       1.0            0.0       1.0   \n3      0.0          0.0        0.0       1.0            0.0       1.0   \n4      0.0          0.0        0.0       1.0            0.0       1.0   \n\n   HS_Weak  HS_Moderate  HS_Strong  \n0      0.0          0.0        1.0  \n1      0.0          1.0        0.0  \n2      0.0          1.0        0.0  \n3      0.0          1.0        0.0  \n4      0.0          1.0        0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>No</th>\n      <th>Tweet</th>\n      <th>HS_Religion</th>\n      <th>HS_Race</th>\n      <th>HS_Physical</th>\n      <th>HS_Gender</th>\n      <th>HS_Other</th>\n      <th>HS_Individual</th>\n      <th>HS_Group</th>\n      <th>HS_Weak</th>\n      <th>HS_Moderate</th>\n      <th>HS_Strong</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Test-1</td>\n      <td>pemerintah sekarang pro asing sudah tidak bisa...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Test-2</td>\n      <td>cebong dungu picek sudah kalah malah gila</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Test-3</td>\n      <td>namanya juga simpang susun bukan bundaran sema...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Test-4</td>\n      <td>yang tidak pakai jilbab komunis megawati sri m...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Test-5</td>\n      <td>ramos yang aku pandang idola dahulu sekarang s...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test = df_test.drop(\"Tweet\", axis=1)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:32:15.950450Z","iopub.execute_input":"2023-06-06T08:32:15.950866Z","iopub.status.idle":"2023-06-06T08:32:15.974876Z","shell.execute_reply.started":"2023-06-06T08:32:15.950833Z","shell.execute_reply":"2023-06-06T08:32:15.973973Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"       No  HS_Religion  HS_Race  HS_Physical  HS_Gender  HS_Other  \\\n0  Test-1          0.0      0.0          0.0        0.0       1.0   \n1  Test-2          0.0      0.0          0.0        0.0       1.0   \n2  Test-3          0.0      0.0          0.0        0.0       1.0   \n3  Test-4          0.0      0.0          0.0        0.0       1.0   \n4  Test-5          0.0      0.0          0.0        0.0       1.0   \n\n   HS_Individual  HS_Group  HS_Weak  HS_Moderate  HS_Strong  \n0            1.0       0.0      0.0          0.0        1.0  \n1            0.0       1.0      0.0          1.0        0.0  \n2            0.0       1.0      0.0          1.0        0.0  \n3            0.0       1.0      0.0          1.0        0.0  \n4            0.0       1.0      0.0          1.0        0.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>No</th>\n      <th>HS_Religion</th>\n      <th>HS_Race</th>\n      <th>HS_Physical</th>\n      <th>HS_Gender</th>\n      <th>HS_Other</th>\n      <th>HS_Individual</th>\n      <th>HS_Group</th>\n      <th>HS_Weak</th>\n      <th>HS_Moderate</th>\n      <th>HS_Strong</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Test-1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Test-2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Test-3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Test-4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Test-5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test.to_csv('final_pred.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-06T08:32:26.408707Z","iopub.execute_input":"2023-06-06T08:32:26.409078Z","iopub.status.idle":"2023-06-06T08:32:26.417266Z","shell.execute_reply.started":"2023-06-06T08:32:26.409048Z","shell.execute_reply":"2023-06-06T08:32:26.416385Z"},"trusted":true},"execution_count":66,"outputs":[]}]}